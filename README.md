**Guardian Data-Pipeline**


**Overview**

This project implements a fully automated data pipeline that fetches data from a public API (guardian API) on a daily basis, stores it in Amazon S3, 
the database is managed by relational database service and sent to datawarehouse (Redshift).
The infrastructure was provisioned using Terraform, while the workflow is managed and scheduled via Apache Airflow.


**Tech Stack**

Python - Scripting

Apache Airflow – Workflow orchestration`

Terraform – Infrastructure as code

AWS S3 – Storage layer

Airbyte - Data Integration

Relational Database Service - Database Management 

Redshift - Datawarehouse

AWS IAM – Access control

AWS Systems Manager (SSM) – Secure credentials storage

Images from the project;

![Image](https://github.com/user-attachments/assets/b0b2a143-7827-404c-b3cf-e60846838a0f)
![Image](https://github.com/user-attachments/assets/e0e49edd-b460-4e8a-b168-2104fa707f10)
![Image](https://github.com/user-attachments/assets/3ac9f04c-0a7f-4d79-a969-0f055428f865)
![Image](https://github.com/user-attachments/assets/9b8871a6-4199-4869-8ef7-a7fb99b3ef52)
![Image](https://github.com/user-attachments/assets/8a8e0fd4-5fe3-4eb1-b2f2-fbe3bdda2568)
![Image](https://github.com/user-attachments/assets/886be722-4dd4-42b6-9ea4-837ee84c431e)

